import numpy as np 
import matplotlib.pyplot as plt 
from tensorflow.keras.datasets import cifar10 
from tensorflow.keras.utils import to_categorical 


## Loading the dataset 
(x_train,y_train),(x_test,y_test) = cifar10.load_data() 
x_train.shape,y_train.shape 
x_test.shape,y_test.shape 


## Dataset Details 
unique, count = np.unique(y_train, return_counts=True) 
print(unique,count) 
unique, count = np.unique(y_test, return_counts=True) 
print(unique,count) 


## Dataset samples 
index=[1,5,12,15,78] 
images=x_train[index] 
labels=y_train[index] 


### Plotting image samples horizontal 
plt.figure(figsize=(10,10)) 
for i in range (len(index)): 
plt.subplot(1,5,i+1) 
plt.imshow(images[i],cmap='gray') 
plt.title(labels[i]) 
plt.axis('off') 
plt.show() 



### Plotting image samples vertical 
plt.figure(figsize=(10,10)) 
for i in range(len(index)): 
plt.subplot(5,1,i+1) 
plt.imshow(images[i]) 
plt.title(labels[i]) 
plt.axis('off') 
plt.show() 
y_train[:5] 
y_train=to_categorical(y_train) 
y_test=to_categorical(y_test) 
input_size=x_train[1].shape[1]*x_train[1].shape[1]*3 
print(input_size) 



## One hot encoding 
y_train=to_categorical(y_train) 
y_test=to_categorical(y_test) 
y_train[:2] 



#2d image needs to converted to 1d 
input_size=x_train[1].shape[1]*x_train[1].shape[1]*3 
print(input_size) 
x_train=np.reshape(x_train,(-1,input_size)) 
x_test=np.reshape(x_test,(-1,input_size)) 
x_train.shape,x_test.shape 



## Normalization 
x_train=x_train/255.0 
x_test=x_test/255.0 
x_train[:5] 



## Model Building 
from tensorflow.keras.models import Sequential 
from tensorflow.keras.layers import Dense, Activation 
model=Sequential() 
model.add(Dense(1024,input_dim=input_size)) 
model.add(Activation('relu')) 
model.add(Dense(512,input_dim=input_size)) 
model.add(Activation('relu')) 
model.add(Dense(256,input_dim=input_size)) 
model.add(Activation('softmax')) 
model.add(Dense(10,input_dim=input_size)) 
model.add(Activation('softmax')) 
model.summary() 
from tensorflow.keras.optimizers import Adam 
model.compile(loss='categorical_crossentropy',optimizer=Adam(learning_rate= 0.001),metrics=['Accuracy']) 
model.fit(x_train,y_train,epochs=25,batch_size=128) 
loss,acc=model.evaluate(x_test,y_test) 
print(loss,acc) 
